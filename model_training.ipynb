{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9461a504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 23:44:38.307680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:38.312118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:38.312497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, re\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sys.path.append(\"./python/\")\n",
    "from tcr_utils import load_tcrs\n",
    "from tcr_transformer import build_transformer_model\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True, lower=False)\n",
    "tokenizer.fit_on_texts('ARNDCEQGHILKMFPSTWYV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d633ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 240:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 180:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "callbacks = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9b1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "tcrs_train_n = load_tcrs(\"data/TrainingData/NormalCDR3.txt\")\n",
    "tcrs_train_t = load_tcrs(\"data/TrainingData/TumorCDR3.txt\")\n",
    "tcrs_test_n = load_tcrs(\"data/TrainingData/NormalCDR3_test.txt\")\n",
    "tcrs_test_t = load_tcrs(\"data/TrainingData/TumorCDR3_test.txt\")\n",
    "\n",
    "# encode TCRs as a sequence of integers to be used as input to the embedding layer\n",
    "X_train = np.concatenate(\n",
    "    [keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(tcrs_train_n), maxlen=20),\n",
    "     keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(tcrs_train_t), maxlen=20)],\n",
    "    axis=0)\n",
    "\n",
    "y_train = np.concatenate(\n",
    "    [np.zeros(len(tcrs_train_n)),\n",
    "     np.ones(len(tcrs_train_t))])\n",
    "\n",
    "X_test = np.concatenate(\n",
    "    [keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(tcrs_test_n), maxlen=20),\n",
    "     keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(tcrs_test_t), maxlen=20)],\n",
    "    axis=0)\n",
    "\n",
    "y_test = np.concatenate(\n",
    "    [np.zeros(len(tcrs_test_n)),\n",
    "     np.ones(len(tcrs_test_t))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e369805c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 23:44:44.265608: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 23:44:44.266465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:44.266862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:44.267190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:44.601808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:44.602158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:44.602463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 23:44:44.602757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4916 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/300\n",
      "2182/2182 [==============================] - 23s 10ms/step - loss: 0.5634 - accuracy: 0.7087 - val_loss: 0.5375 - val_accuracy: 0.7291 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.5119 - accuracy: 0.7484 - val_loss: 0.4632 - val_accuracy: 0.7829 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4994 - accuracy: 0.7550 - val_loss: 0.4490 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4930 - accuracy: 0.7598 - val_loss: 0.4839 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4853 - accuracy: 0.7654 - val_loss: 0.4349 - val_accuracy: 0.8005 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4783 - accuracy: 0.7696 - val_loss: 0.4696 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4722 - accuracy: 0.7727 - val_loss: 0.4242 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4682 - accuracy: 0.7748 - val_loss: 0.4153 - val_accuracy: 0.8092 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4609 - accuracy: 0.7779 - val_loss: 0.4180 - val_accuracy: 0.8114 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4567 - accuracy: 0.7821 - val_loss: 0.4138 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4537 - accuracy: 0.7834 - val_loss: 0.4194 - val_accuracy: 0.8094 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4492 - accuracy: 0.7863 - val_loss: 0.4098 - val_accuracy: 0.8135 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4467 - accuracy: 0.7876 - val_loss: 0.4160 - val_accuracy: 0.8072 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4426 - accuracy: 0.7915 - val_loss: 0.4188 - val_accuracy: 0.8084 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4384 - accuracy: 0.7935 - val_loss: 0.4333 - val_accuracy: 0.7977 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4379 - accuracy: 0.7919 - val_loss: 0.4027 - val_accuracy: 0.8165 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4345 - accuracy: 0.7940 - val_loss: 0.3952 - val_accuracy: 0.8215 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4323 - accuracy: 0.7961 - val_loss: 0.4041 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4289 - accuracy: 0.7977 - val_loss: 0.3869 - val_accuracy: 0.8243 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4273 - accuracy: 0.7993 - val_loss: 0.3934 - val_accuracy: 0.8196 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4271 - accuracy: 0.7979 - val_loss: 0.3863 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4242 - accuracy: 0.7993 - val_loss: 0.3900 - val_accuracy: 0.8217 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4216 - accuracy: 0.8012 - val_loss: 0.3832 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4212 - accuracy: 0.7995 - val_loss: 0.4052 - val_accuracy: 0.8146 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 25/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4181 - accuracy: 0.8041 - val_loss: 0.4391 - val_accuracy: 0.7936 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4165 - accuracy: 0.8042 - val_loss: 0.3849 - val_accuracy: 0.8251 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4145 - accuracy: 0.8032 - val_loss: 0.3849 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4142 - accuracy: 0.8063 - val_loss: 0.3843 - val_accuracy: 0.8267 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4131 - accuracy: 0.8064 - val_loss: 0.3762 - val_accuracy: 0.8299 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4095 - accuracy: 0.8084 - val_loss: 0.3843 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 31/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4089 - accuracy: 0.8092 - val_loss: 0.3779 - val_accuracy: 0.8304 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 32/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4067 - accuracy: 0.8097 - val_loss: 0.3820 - val_accuracy: 0.8242 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 33/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4065 - accuracy: 0.8089 - val_loss: 0.3757 - val_accuracy: 0.8312 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 34/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4035 - accuracy: 0.8108 - val_loss: 0.3803 - val_accuracy: 0.8272 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 35/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4034 - accuracy: 0.8118 - val_loss: 0.3853 - val_accuracy: 0.8227 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 36/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4015 - accuracy: 0.8135 - val_loss: 0.3779 - val_accuracy: 0.8262 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 37/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.4016 - accuracy: 0.8128 - val_loss: 0.3835 - val_accuracy: 0.8251 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 38/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3996 - accuracy: 0.8138 - val_loss: 0.3857 - val_accuracy: 0.8254 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 39/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3990 - accuracy: 0.8133 - val_loss: 0.3704 - val_accuracy: 0.8319 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 40/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3969 - accuracy: 0.8137 - val_loss: 0.3858 - val_accuracy: 0.8259 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 41/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3949 - accuracy: 0.8162 - val_loss: 0.3730 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 42/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3977 - accuracy: 0.8143 - val_loss: 0.3761 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 43/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3934 - accuracy: 0.8174 - val_loss: 0.3687 - val_accuracy: 0.8353 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 44/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3944 - accuracy: 0.8166 - val_loss: 0.3677 - val_accuracy: 0.8342 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 45/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3920 - accuracy: 0.8179 - val_loss: 0.3682 - val_accuracy: 0.8340 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 46/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3929 - accuracy: 0.8165 - val_loss: 0.3653 - val_accuracy: 0.8328 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 47/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3897 - accuracy: 0.8195 - val_loss: 0.3706 - val_accuracy: 0.8318 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 48/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3903 - accuracy: 0.8186 - val_loss: 0.3693 - val_accuracy: 0.8323 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 49/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3906 - accuracy: 0.8177 - val_loss: 0.3637 - val_accuracy: 0.8347 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 50/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3883 - accuracy: 0.8189 - val_loss: 0.3667 - val_accuracy: 0.8352 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 51/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3887 - accuracy: 0.8193 - val_loss: 0.3755 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 52/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3878 - accuracy: 0.8204 - val_loss: 0.3620 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 53/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3849 - accuracy: 0.8221 - val_loss: 0.3635 - val_accuracy: 0.8372 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 54/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3848 - accuracy: 0.8224 - val_loss: 0.3676 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 55/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3838 - accuracy: 0.8222 - val_loss: 0.3604 - val_accuracy: 0.8353 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 56/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3826 - accuracy: 0.8235 - val_loss: 0.3646 - val_accuracy: 0.8351 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 57/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3825 - accuracy: 0.8226 - val_loss: 0.3684 - val_accuracy: 0.8329 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 58/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3833 - accuracy: 0.8227 - val_loss: 0.3884 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 59/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3802 - accuracy: 0.8245 - val_loss: 0.3618 - val_accuracy: 0.8350 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 60/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3806 - accuracy: 0.8234 - val_loss: 0.3806 - val_accuracy: 0.8271 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 61/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3798 - accuracy: 0.8259 - val_loss: 0.3833 - val_accuracy: 0.8245 - lr: 0.0010\n",
      "Learning rate:  0.0001\n",
      "Epoch 62/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3587 - accuracy: 0.8357 - val_loss: 0.3568 - val_accuracy: 0.8390 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 63/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3497 - accuracy: 0.8404 - val_loss: 0.3520 - val_accuracy: 0.8418 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 64/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3452 - accuracy: 0.8419 - val_loss: 0.3549 - val_accuracy: 0.8398 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 65/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3429 - accuracy: 0.8436 - val_loss: 0.3478 - val_accuracy: 0.8431 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 66/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3392 - accuracy: 0.8454 - val_loss: 0.3555 - val_accuracy: 0.8400 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 67/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3393 - accuracy: 0.8462 - val_loss: 0.3479 - val_accuracy: 0.8430 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 68/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3374 - accuracy: 0.8473 - val_loss: 0.3474 - val_accuracy: 0.8436 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 69/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3357 - accuracy: 0.8484 - val_loss: 0.3567 - val_accuracy: 0.8415 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 70/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3344 - accuracy: 0.8486 - val_loss: 0.3517 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 71/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3325 - accuracy: 0.8493 - val_loss: 0.3509 - val_accuracy: 0.8434 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 72/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.3331 - accuracy: 0.8492 - val_loss: 0.3513 - val_accuracy: 0.8433 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 73/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3325 - accuracy: 0.8497 - val_loss: 0.3431 - val_accuracy: 0.8464 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 74/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3300 - accuracy: 0.8510 - val_loss: 0.3538 - val_accuracy: 0.8429 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 75/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3298 - accuracy: 0.8511 - val_loss: 0.3502 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 76/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3288 - accuracy: 0.8510 - val_loss: 0.3488 - val_accuracy: 0.8442 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 77/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3283 - accuracy: 0.8519 - val_loss: 0.3436 - val_accuracy: 0.8462 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 78/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3291 - accuracy: 0.8511 - val_loss: 0.3461 - val_accuracy: 0.8451 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 79/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3277 - accuracy: 0.8528 - val_loss: 0.3459 - val_accuracy: 0.8453 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 80/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3264 - accuracy: 0.8530 - val_loss: 0.3465 - val_accuracy: 0.8465 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 81/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3271 - accuracy: 0.8526 - val_loss: 0.3497 - val_accuracy: 0.8444 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3250 - accuracy: 0.8529 - val_loss: 0.3406 - val_accuracy: 0.8477 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3248 - accuracy: 0.8535 - val_loss: 0.3461 - val_accuracy: 0.8471 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3248 - accuracy: 0.8536 - val_loss: 0.3427 - val_accuracy: 0.8471 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3232 - accuracy: 0.8547 - val_loss: 0.3403 - val_accuracy: 0.8482 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3235 - accuracy: 0.8541 - val_loss: 0.3526 - val_accuracy: 0.8444 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.3216 - accuracy: 0.8557 - val_loss: 0.3449 - val_accuracy: 0.8474 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3229 - accuracy: 0.8548 - val_loss: 0.3411 - val_accuracy: 0.8485 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3210 - accuracy: 0.8563 - val_loss: 0.3463 - val_accuracy: 0.8478 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3209 - accuracy: 0.8552 - val_loss: 0.3459 - val_accuracy: 0.8477 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3209 - accuracy: 0.8558 - val_loss: 0.3447 - val_accuracy: 0.8474 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3194 - accuracy: 0.8564 - val_loss: 0.3414 - val_accuracy: 0.8494 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3190 - accuracy: 0.8573 - val_loss: 0.3426 - val_accuracy: 0.8487 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3194 - accuracy: 0.8570 - val_loss: 0.3454 - val_accuracy: 0.8474 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3180 - accuracy: 0.8572 - val_loss: 0.3445 - val_accuracy: 0.8474 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3187 - accuracy: 0.8560 - val_loss: 0.3421 - val_accuracy: 0.8495 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3172 - accuracy: 0.8572 - val_loss: 0.3505 - val_accuracy: 0.8462 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3163 - accuracy: 0.8580 - val_loss: 0.3420 - val_accuracy: 0.8495 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3174 - accuracy: 0.8584 - val_loss: 0.3432 - val_accuracy: 0.8497 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3160 - accuracy: 0.8584 - val_loss: 0.3441 - val_accuracy: 0.8480 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 101/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3152 - accuracy: 0.8598 - val_loss: 0.3412 - val_accuracy: 0.8499 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 102/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3143 - accuracy: 0.8594 - val_loss: 0.3429 - val_accuracy: 0.8488 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 103/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3161 - accuracy: 0.8583 - val_loss: 0.3370 - val_accuracy: 0.8515 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 104/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3157 - accuracy: 0.8584 - val_loss: 0.3424 - val_accuracy: 0.8491 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 105/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3155 - accuracy: 0.8590 - val_loss: 0.3434 - val_accuracy: 0.8495 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 106/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3138 - accuracy: 0.8598 - val_loss: 0.3400 - val_accuracy: 0.8507 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 107/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3144 - accuracy: 0.8586 - val_loss: 0.3444 - val_accuracy: 0.8490 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 108/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3132 - accuracy: 0.8602 - val_loss: 0.3428 - val_accuracy: 0.8485 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 109/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3118 - accuracy: 0.8603 - val_loss: 0.3397 - val_accuracy: 0.8493 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 110/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3126 - accuracy: 0.8599 - val_loss: 0.3385 - val_accuracy: 0.8515 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 111/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3113 - accuracy: 0.8608 - val_loss: 0.3492 - val_accuracy: 0.8461 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 112/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3112 - accuracy: 0.8606 - val_loss: 0.3443 - val_accuracy: 0.8491 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 113/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3106 - accuracy: 0.8616 - val_loss: 0.3478 - val_accuracy: 0.8486 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 114/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3114 - accuracy: 0.8602 - val_loss: 0.3423 - val_accuracy: 0.8499 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 115/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3098 - accuracy: 0.8611 - val_loss: 0.3451 - val_accuracy: 0.8491 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 116/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3109 - accuracy: 0.8606 - val_loss: 0.3507 - val_accuracy: 0.8462 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 117/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3094 - accuracy: 0.8623 - val_loss: 0.3387 - val_accuracy: 0.8519 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 118/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3086 - accuracy: 0.8629 - val_loss: 0.3385 - val_accuracy: 0.8518 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 119/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3098 - accuracy: 0.8613 - val_loss: 0.3424 - val_accuracy: 0.8501 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 120/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3080 - accuracy: 0.8618 - val_loss: 0.3453 - val_accuracy: 0.8499 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 121/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3084 - accuracy: 0.8613 - val_loss: 0.3426 - val_accuracy: 0.8513 - lr: 1.0000e-04\n",
      "Learning rate:  1e-05\n",
      "Epoch 122/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3062 - accuracy: 0.8637 - val_loss: 0.3412 - val_accuracy: 0.8505 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 123/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3040 - accuracy: 0.8637 - val_loss: 0.3401 - val_accuracy: 0.8514 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 124/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3029 - accuracy: 0.8651 - val_loss: 0.3421 - val_accuracy: 0.8509 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 125/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3019 - accuracy: 0.8658 - val_loss: 0.3408 - val_accuracy: 0.8513 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 126/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3020 - accuracy: 0.8649 - val_loss: 0.3425 - val_accuracy: 0.8507 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 127/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3029 - accuracy: 0.8644 - val_loss: 0.3421 - val_accuracy: 0.8507 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 128/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3026 - accuracy: 0.8643 - val_loss: 0.3418 - val_accuracy: 0.8514 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 129/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3022 - accuracy: 0.8642 - val_loss: 0.3409 - val_accuracy: 0.8510 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 130/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3009 - accuracy: 0.8663 - val_loss: 0.3412 - val_accuracy: 0.8512 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 131/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3026 - accuracy: 0.8647 - val_loss: 0.3382 - val_accuracy: 0.8518 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 132/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3016 - accuracy: 0.8655 - val_loss: 0.3415 - val_accuracy: 0.8509 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 133/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3010 - accuracy: 0.8653 - val_loss: 0.3386 - val_accuracy: 0.8524 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 134/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3010 - accuracy: 0.8659 - val_loss: 0.3427 - val_accuracy: 0.8510 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 135/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.3016 - accuracy: 0.8657 - val_loss: 0.3403 - val_accuracy: 0.8521 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 136/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.3010 - accuracy: 0.8649 - val_loss: 0.3403 - val_accuracy: 0.8520 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 137/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3021 - accuracy: 0.8654 - val_loss: 0.3420 - val_accuracy: 0.8513 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 138/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2995 - accuracy: 0.8674 - val_loss: 0.3420 - val_accuracy: 0.8511 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 139/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3018 - accuracy: 0.8653 - val_loss: 0.3435 - val_accuracy: 0.8505 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 140/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3010 - accuracy: 0.8657 - val_loss: 0.3414 - val_accuracy: 0.8512 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 141/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2993 - accuracy: 0.8678 - val_loss: 0.3410 - val_accuracy: 0.8512 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 142/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.3016 - accuracy: 0.8656 - val_loss: 0.3443 - val_accuracy: 0.8502 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 143/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3004 - accuracy: 0.8664 - val_loss: 0.3406 - val_accuracy: 0.8516 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 144/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3010 - accuracy: 0.8659 - val_loss: 0.3411 - val_accuracy: 0.8518 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 145/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2997 - accuracy: 0.8667 - val_loss: 0.3418 - val_accuracy: 0.8515 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 146/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.3001 - accuracy: 0.8671 - val_loss: 0.3429 - val_accuracy: 0.8512 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 147/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2999 - accuracy: 0.8663 - val_loss: 0.3399 - val_accuracy: 0.8521 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 148/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.3011 - accuracy: 0.8656 - val_loss: 0.3418 - val_accuracy: 0.8511 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 149/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2999 - accuracy: 0.8660 - val_loss: 0.3417 - val_accuracy: 0.8515 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 150/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3014 - accuracy: 0.8657 - val_loss: 0.3385 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 151/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2996 - accuracy: 0.8680 - val_loss: 0.3400 - val_accuracy: 0.8518 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 152/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2998 - accuracy: 0.8663 - val_loss: 0.3413 - val_accuracy: 0.8515 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 153/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2983 - accuracy: 0.8678 - val_loss: 0.3396 - val_accuracy: 0.8517 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 154/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2993 - accuracy: 0.8676 - val_loss: 0.3422 - val_accuracy: 0.8513 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 155/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3015 - accuracy: 0.8646 - val_loss: 0.3422 - val_accuracy: 0.8511 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 156/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2997 - accuracy: 0.8672 - val_loss: 0.3400 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 157/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3003 - accuracy: 0.8656 - val_loss: 0.3406 - val_accuracy: 0.8520 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 158/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2995 - accuracy: 0.8660 - val_loss: 0.3403 - val_accuracy: 0.8516 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 159/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3003 - accuracy: 0.8664 - val_loss: 0.3400 - val_accuracy: 0.8526 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 160/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2986 - accuracy: 0.8676 - val_loss: 0.3419 - val_accuracy: 0.8516 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 161/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2999 - accuracy: 0.8667 - val_loss: 0.3419 - val_accuracy: 0.8518 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 162/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3016 - accuracy: 0.8643 - val_loss: 0.3414 - val_accuracy: 0.8524 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 163/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3003 - accuracy: 0.8660 - val_loss: 0.3420 - val_accuracy: 0.8515 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 164/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2997 - accuracy: 0.8670 - val_loss: 0.3403 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 165/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2993 - accuracy: 0.8668 - val_loss: 0.3411 - val_accuracy: 0.8526 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 166/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2990 - accuracy: 0.8672 - val_loss: 0.3422 - val_accuracy: 0.8525 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 167/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2991 - accuracy: 0.8655 - val_loss: 0.3401 - val_accuracy: 0.8528 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 168/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2980 - accuracy: 0.8685 - val_loss: 0.3429 - val_accuracy: 0.8523 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 169/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3002 - accuracy: 0.8662 - val_loss: 0.3405 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 170/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2991 - accuracy: 0.8661 - val_loss: 0.3411 - val_accuracy: 0.8519 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 171/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2982 - accuracy: 0.8673 - val_loss: 0.3416 - val_accuracy: 0.8526 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 172/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8680 - val_loss: 0.3396 - val_accuracy: 0.8524 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 173/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2985 - accuracy: 0.8682 - val_loss: 0.3410 - val_accuracy: 0.8521 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 174/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2987 - accuracy: 0.8665 - val_loss: 0.3397 - val_accuracy: 0.8523 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 175/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2970 - accuracy: 0.8691 - val_loss: 0.3412 - val_accuracy: 0.8518 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 176/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2996 - accuracy: 0.8658 - val_loss: 0.3388 - val_accuracy: 0.8526 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-05\n",
      "Epoch 177/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8677 - val_loss: 0.3415 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 178/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2988 - accuracy: 0.8664 - val_loss: 0.3417 - val_accuracy: 0.8519 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 179/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.3010 - accuracy: 0.8667 - val_loss: 0.3410 - val_accuracy: 0.8520 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 180/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2997 - accuracy: 0.8660 - val_loss: 0.3387 - val_accuracy: 0.8530 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 181/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2979 - accuracy: 0.8672 - val_loss: 0.3417 - val_accuracy: 0.8517 - lr: 1.0000e-05\n",
      "Learning rate:  1e-06\n",
      "Epoch 182/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8677 - val_loss: 0.3412 - val_accuracy: 0.8518 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 183/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2990 - accuracy: 0.8662 - val_loss: 0.3407 - val_accuracy: 0.8522 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 184/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2986 - accuracy: 0.8670 - val_loss: 0.3407 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 185/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2988 - accuracy: 0.8675 - val_loss: 0.3408 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 186/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2957 - accuracy: 0.8679 - val_loss: 0.3408 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 187/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2989 - accuracy: 0.8666 - val_loss: 0.3409 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 188/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2974 - accuracy: 0.8673 - val_loss: 0.3405 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 189/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2994 - accuracy: 0.8679 - val_loss: 0.3406 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 190/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2982 - accuracy: 0.8673 - val_loss: 0.3405 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 191/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2983 - accuracy: 0.8688 - val_loss: 0.3405 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 192/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2993 - accuracy: 0.8658 - val_loss: 0.3405 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 193/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2971 - accuracy: 0.8678 - val_loss: 0.3405 - val_accuracy: 0.8522 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 194/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2991 - accuracy: 0.8674 - val_loss: 0.3403 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 195/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2988 - accuracy: 0.8678 - val_loss: 0.3405 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 196/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2982 - accuracy: 0.8679 - val_loss: 0.3403 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 197/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2989 - accuracy: 0.8666 - val_loss: 0.3403 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 198/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2997 - accuracy: 0.8672 - val_loss: 0.3404 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 199/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2965 - accuracy: 0.8686 - val_loss: 0.3404 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 200/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2971 - accuracy: 0.8679 - val_loss: 0.3404 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 201/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8676 - val_loss: 0.3404 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 202/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2984 - accuracy: 0.8677 - val_loss: 0.3403 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 203/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2978 - accuracy: 0.8668 - val_loss: 0.3405 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 204/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2977 - accuracy: 0.8667 - val_loss: 0.3406 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 205/300\n",
      "2182/2182 [==============================] - 21s 9ms/step - loss: 0.2969 - accuracy: 0.8674 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 206/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2979 - accuracy: 0.8670 - val_loss: 0.3406 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 207/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2978 - accuracy: 0.8678 - val_loss: 0.3406 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 208/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2987 - accuracy: 0.8673 - val_loss: 0.3408 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 209/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2972 - accuracy: 0.8684 - val_loss: 0.3407 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 210/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2979 - accuracy: 0.8672 - val_loss: 0.3409 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 211/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2969 - accuracy: 0.8678 - val_loss: 0.3408 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 212/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2970 - accuracy: 0.8680 - val_loss: 0.3407 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 213/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2987 - accuracy: 0.8675 - val_loss: 0.3409 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 214/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8670 - val_loss: 0.3408 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 215/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2978 - accuracy: 0.8686 - val_loss: 0.3407 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 216/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2987 - accuracy: 0.8673 - val_loss: 0.3409 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 217/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2964 - accuracy: 0.8682 - val_loss: 0.3406 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 218/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2990 - accuracy: 0.8679 - val_loss: 0.3403 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 219/300\n",
      "2182/2182 [==============================] - 23s 11ms/step - loss: 0.2990 - accuracy: 0.8666 - val_loss: 0.3407 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2977 - accuracy: 0.8659 - val_loss: 0.3406 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 221/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2964 - accuracy: 0.8678 - val_loss: 0.3405 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 222/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2968 - accuracy: 0.8675 - val_loss: 0.3406 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 223/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2987 - accuracy: 0.8671 - val_loss: 0.3408 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 224/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2995 - accuracy: 0.8671 - val_loss: 0.3407 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 225/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2972 - accuracy: 0.8682 - val_loss: 0.3405 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 226/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2979 - accuracy: 0.8679 - val_loss: 0.3403 - val_accuracy: 0.8527 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 227/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2978 - accuracy: 0.8671 - val_loss: 0.3405 - val_accuracy: 0.8526 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 228/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2971 - accuracy: 0.8670 - val_loss: 0.3407 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 229/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2973 - accuracy: 0.8688 - val_loss: 0.3407 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 230/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2964 - accuracy: 0.8685 - val_loss: 0.3407 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 231/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2981 - accuracy: 0.8674 - val_loss: 0.3407 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 232/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2984 - accuracy: 0.8674 - val_loss: 0.3410 - val_accuracy: 0.8522 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 233/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2988 - accuracy: 0.8670 - val_loss: 0.3406 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 234/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2980 - accuracy: 0.8673 - val_loss: 0.3407 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 235/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2981 - accuracy: 0.8672 - val_loss: 0.3408 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 236/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2981 - accuracy: 0.8666 - val_loss: 0.3405 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 237/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2981 - accuracy: 0.8670 - val_loss: 0.3403 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 238/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2962 - accuracy: 0.8678 - val_loss: 0.3404 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 239/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2991 - accuracy: 0.8665 - val_loss: 0.3405 - val_accuracy: 0.8525 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 240/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2988 - accuracy: 0.8672 - val_loss: 0.3404 - val_accuracy: 0.8524 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 241/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2984 - accuracy: 0.8663 - val_loss: 0.3405 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
      "Learning rate:  5e-07\n",
      "Epoch 242/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2971 - accuracy: 0.8678 - val_loss: 0.3405 - val_accuracy: 0.8524 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 243/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2980 - accuracy: 0.8678 - val_loss: 0.3407 - val_accuracy: 0.8523 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 244/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2968 - accuracy: 0.8682 - val_loss: 0.3406 - val_accuracy: 0.8524 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 245/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2979 - accuracy: 0.8674 - val_loss: 0.3407 - val_accuracy: 0.8524 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 246/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2966 - accuracy: 0.8684 - val_loss: 0.3407 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 247/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2986 - accuracy: 0.8672 - val_loss: 0.3408 - val_accuracy: 0.8524 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 248/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2971 - accuracy: 0.8680 - val_loss: 0.3409 - val_accuracy: 0.8523 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 249/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2973 - accuracy: 0.8670 - val_loss: 0.3408 - val_accuracy: 0.8524 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 250/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2969 - accuracy: 0.8673 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 251/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2994 - accuracy: 0.8668 - val_loss: 0.3407 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 252/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2990 - accuracy: 0.8675 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 253/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2951 - accuracy: 0.8693 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 254/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8686 - val_loss: 0.3408 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 255/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2992 - accuracy: 0.8658 - val_loss: 0.3407 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 256/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2965 - accuracy: 0.8681 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 257/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2976 - accuracy: 0.8673 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 258/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2981 - accuracy: 0.8680 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 259/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2985 - accuracy: 0.8666 - val_loss: 0.3407 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 260/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2972 - accuracy: 0.8678 - val_loss: 0.3406 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 261/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2974 - accuracy: 0.8676 - val_loss: 0.3406 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 262/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2991 - accuracy: 0.8658 - val_loss: 0.3406 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 263/300\n",
      "2182/2182 [==============================] - 23s 11ms/step - loss: 0.2962 - accuracy: 0.8690 - val_loss: 0.3405 - val_accuracy: 0.8528 - lr: 5.0000e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  5e-07\n",
      "Epoch 264/300\n",
      "2182/2182 [==============================] - 26s 12ms/step - loss: 0.2981 - accuracy: 0.8677 - val_loss: 0.3405 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 265/300\n",
      "2182/2182 [==============================] - 26s 12ms/step - loss: 0.2994 - accuracy: 0.8665 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 266/300\n",
      "2182/2182 [==============================] - 24s 11ms/step - loss: 0.2969 - accuracy: 0.8673 - val_loss: 0.3404 - val_accuracy: 0.8529 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 267/300\n",
      "2182/2182 [==============================] - 26s 12ms/step - loss: 0.2983 - accuracy: 0.8683 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 268/300\n",
      "2182/2182 [==============================] - 23s 11ms/step - loss: 0.2983 - accuracy: 0.8682 - val_loss: 0.3405 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 269/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2971 - accuracy: 0.8675 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 270/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2980 - accuracy: 0.8673 - val_loss: 0.3406 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 271/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2994 - accuracy: 0.8670 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 272/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2984 - accuracy: 0.8665 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 273/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2980 - accuracy: 0.8662 - val_loss: 0.3405 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 274/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2995 - accuracy: 0.8674 - val_loss: 0.3406 - val_accuracy: 0.8524 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 275/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2976 - accuracy: 0.8674 - val_loss: 0.3405 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 276/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2984 - accuracy: 0.8685 - val_loss: 0.3405 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 277/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2985 - accuracy: 0.8677 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 278/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2974 - accuracy: 0.8682 - val_loss: 0.3405 - val_accuracy: 0.8526 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 279/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2970 - accuracy: 0.8677 - val_loss: 0.3405 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 280/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2976 - accuracy: 0.8675 - val_loss: 0.3406 - val_accuracy: 0.8525 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 281/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2971 - accuracy: 0.8688 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 282/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8678 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 283/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2970 - accuracy: 0.8684 - val_loss: 0.3405 - val_accuracy: 0.8529 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 284/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2979 - accuracy: 0.8688 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 285/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2977 - accuracy: 0.8671 - val_loss: 0.3404 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 286/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2978 - accuracy: 0.8669 - val_loss: 0.3403 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 287/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2969 - accuracy: 0.8688 - val_loss: 0.3404 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 288/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2970 - accuracy: 0.8683 - val_loss: 0.3403 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 289/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2962 - accuracy: 0.8684 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 290/300\n",
      "2182/2182 [==============================] - 22s 10ms/step - loss: 0.2961 - accuracy: 0.8690 - val_loss: 0.3403 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 291/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2983 - accuracy: 0.8680 - val_loss: 0.3403 - val_accuracy: 0.8529 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 292/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2979 - accuracy: 0.8683 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 293/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2981 - accuracy: 0.8679 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 294/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8676 - val_loss: 0.3405 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 295/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2977 - accuracy: 0.8677 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 296/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2982 - accuracy: 0.8675 - val_loss: 0.3406 - val_accuracy: 0.8527 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 297/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2983 - accuracy: 0.8669 - val_loss: 0.3404 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 298/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2987 - accuracy: 0.8672 - val_loss: 0.3403 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 299/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2975 - accuracy: 0.8681 - val_loss: 0.3403 - val_accuracy: 0.8528 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 300/300\n",
      "2182/2182 [==============================] - 21s 10ms/step - loss: 0.2980 - accuracy: 0.8684 - val_loss: 0.3404 - val_accuracy: 0.8527 - lr: 5.0000e-07\n"
     ]
    }
   ],
   "source": [
    "transformer_mod = build_transformer_model()\n",
    "\n",
    "history = transformer_mod.fit(\n",
    "    X_train, y_train,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    epochs=300,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7526206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).drop(\"lr\", axis=1).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.ylim(0,1)\n",
    "#plt.savefig('figures/training.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56116a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
